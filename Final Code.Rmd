---
title: "Final Code"
output: github_document
date: "2025-11-21"
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(haven)
library(glmnet)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Import Datasets
Please note for all those who use this... run once and only once. Then add back in the # to comment this chunk out.
```{r, eval=FALSE}
rat_df =
read_csv("data_not_for_github/NYC_rats.csv") |>
janitor::clean_names() |>
mutate(created_date = ymd_hms(created_date)) |>
filter(year(created_date) == 2025) |>
  rename(zipcode = incident_zip) |>
  select(created_date, zipcode, borough, latitude, longitude, location_type)

restaurant_df =
read_csv("data_not_for_github/NYC_restaurant.csv") |>
janitor::clean_names() |>
mutate(inspection_date = mdy(inspection_date))   |>
filter(year(inspection_date) == 2025) |>
  select(dba, boro, zipcode, inspection_date, violation_description, grade, latitude, longitude)


dir.create("data_small", showWarnings = FALSE)
write_csv(rat_df, "data_small/rat_df_2025_small.csv")
write_csv(restaurant_df, "data_small/restaurant_df_2025_small.csv")
```

```{r}
rat_df <- read_csv("data_small/rat_df_2025_small.csv")
restaurant_df <- read_csv("data_small/restaurant_df_2025_small.csv")
```

Our decision to use only 2025 data provides a current snapshot of rat sightings and restaurant inspections in NYC. This ensures relevance but means we cannot analyze longitudinal trends in rat populations, and some restaurants may be absent from our dataset if they weren't inspected during this specific time period.


## Merge Summaries by Zipcode
Note that we can run our analyses without doing this, but this simplifies our data down to just counts by zipcode.THIS DOES NOT INCLUDE LAT AND LONG....for mapping purposes may need to use individual datasets above!
```{r}
# Count rats per zipcode
rat_summary <- rat_df |>
  group_by(zipcode) |>
  summarise(ratreport_count = n(), .groups = "drop")

# Count restaurants per zipcode by grade
restaurant_summary <- restaurant_df |>
  group_by(zipcode) |>
  summarise(
    restaurant_count = n(),
    grade_A = sum(grade == "A", na.rm = TRUE),
    grade_B = sum(grade == "B", na.rm = TRUE),
    grade_C = sum(grade == "C", na.rm = TRUE)
  , .groups = "drop")

# Join
zipcode_summary <- rat_summary |>
  left_join(restaurant_summary, by = "zipcode")
```

## Regressing Rat Sightings Count Against Pizza Restaurant Count

```{r}
# Fitting a linear regression
fit = lm(ratreport_count ~ restaurant_count, data = zipcode_summary)

# Examining the regression output
fit |> 
  broom::tidy() |> 
  select(term, estimate, p.value) |> 
  knitr::kable(digits = 3)

# Obtaining r-squared, p-value
fit |> 
  broom::glance() |> 
  select(r.squared, p.value) |> 
  knitr::kable(digits = 3)

# Looking at the residuals vs. fitted values
zipcode_summary |> 
  modelr::add_residuals(fit) |> 
  modelr::add_predictions(fit) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() 

# Plotting rat sightings count vs. restaurant count
zipcode_summary |> 
  ggplot(aes(x = restaurant_count, y = ratreport_count)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  labs(
    x = "# Pizza Restaurants",
    y = "# Rat Sighting Reports",
    title = "Rat Sightings vs. Pizza Restaurants"
 )
```


