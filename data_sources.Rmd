---
title: "Data Sources"
output: 
  html_document:
    code_folding: hide

---

```{r setup, include = FALSE}


library(tidyverse)
library(dplyr)
library(readxl)
library(haven)
library(glmnet)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


We used two datasets from NYC Open Data (2025 only):

- <a href="https://data.cityofnewyork.us/Social-Services/Rat-Sightings/3q43-55fe/about_data">311 Rat Sightings</a>: Includes the date of the report, borough, ZIP code, and precise coordinates of each sighting. These data represent resident-reported encounters with rats, not direct biological surveys, and therefore reflect patterns in human observation as well as true rodent presence.

- <a href="https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/about_data ">NYC Restaurant Inspection Results</a>: Contains restaurant name, location, cuisine type, inspection date, assigned grade, and description of any violations. Restaurant inspections occur at uneven intervals, and not all establishments receive inspections every year. As a result, some ZIP codes may appear to have fewer restaurants simply due to inspection timing rather than true absence. We identified pizza-serving establishments based on keywords in their listed names. Our search terms for pizza restaurants include "pizza", "pizzeria", and "slice". Ideally this would cover all pizza joints but we recognize that some may fall under various other names!


Our decision to use only 2025 data was driven primarily by the size of the full NYC Open Data datasets and a desire to provide a current snapshot of rat sightings and pizza restaurant inspections. Both the 311 Rat Sightings dataset and the Restaurant Inspection Results dataset contain hundreds of thousands of records spanning many years, which makes processing the entire timespan computationally intensive and unnecessary for the scope of our project. Limiting our analysis to 2025 allowed us to work with a more manageable dataset while still capturing a meaningful and current snapshot of rat activity and restaurant inspections across NYC. This choice, however, comes with tradeoffs: we are unable to analyze longitudinal trends in rat populations, seasonal variation across multiple years, or changes in inspection practices over time. Additionally, restaurants that were not inspected during 2025, even if they were operating, do not appear in our dataset. As a result, our findings reflect conditions specific to the 2025 inspection cycle rather than multi-year patterns or absolute restaurant counts.

## Import Datasets from NYC Open Data

All data cleaning and aggregation steps were conducted in R, and every transformation is documented in the code chunks below. Raw datasets are stored in a private folder (data_not_for_github) due to size and cleaned subsets are saved in data_small/ for reproducibility.

```{r, eval=FALSE, message = FALSE, warning = FALSE}
rat_df =
read_csv("data_not_for_github/NYC_rats.csv") |>
janitor::clean_names() |>
mutate(created_date = ymd_hms(created_date)) |>
filter(year(created_date) == 2025) |>
  rename(zipcode = incident_zip) |>
  select(created_date, zipcode, borough, latitude, longitude, location_type)

restaurant_df =
read_csv("data_not_for_github/NYC_restaurant.csv") |>
janitor::clean_names() |>
mutate(inspection_date = mdy(inspection_date))   |>
filter(year(inspection_date) == 2025) |>
  select(dba, boro, zipcode, inspection_date, violation_description, grade, latitude, longitude)


dir.create("data_small", showWarnings = FALSE)
write_csv(rat_df, "data_small/rat_df_2025_small.csv")
write_csv(restaurant_df, "data_small/restaurant_df_2025_small.csv")
```

```{r, eval = FALSE}
rat_df <- read_csv("data_small/rat_df_2025_small.csv")
restaurant_df <- read_csv("data_small/restaurant_df_2025_small.csv")

# Limit to only pizza joints
pizza_df =
  restaurant_df |>
  filter((str_detect(str_to_lower(dba), 
                    "pizza|pizzeria|slice")))
```


## Create Summaries by Zipcode

Next, we created a small dataframe that summarized counts of rat sightings and pizza restaurants by zipcode. Note that we can run our analyses without doing this, but this simplifies our data down to just counts by zipcode. We aggregated rat sightings and pizza restaurants to the zipcode level because: zipcodes provide a consistent administrative boundary available in both datasets, they allow straightforward merging across sources and are intuitive for interpretation, and they are frequently used in NYC health and housing analyses.However,  zipcodes are not demographic boundaries, nor do they capture ecological variation as precisely as census tracts or community districts. 

Our `zipcode_summary` dataset includes the following information on 73 NYC zipcodes. 

- `zipcode`: Zipcode number
- `ratreport_count`: Number of rat sightings in given zipcode
- `pizzarestaurant_count`: Number of pizza restaurants in given zipcode
- `Pizza_A`: Number of pizza restaurants given A rating during inspection
- `Pizza_B`: Number of pizza restaurants given B rating during inspection
- `Pizza_C`: Number of pizza restaurants given C rating during inspection

```{r, eval = FALSE}
# Count rats per zipcode
rat_summary <- rat_df |>
  group_by(zipcode) |>
  summarise(ratreport_count = n(), .groups = "drop")

# Count restaurants per zipcode by grade
pizza_summary <- pizza_df |>
  group_by(zipcode) |>
  summarise(
    pizzarestaurant_count = n(),
    pizza_A = sum(grade == "A", na.rm = TRUE),
    pizza_B = sum(grade == "B", na.rm = TRUE),
    pizza_C = sum(grade == "C", na.rm = TRUE)
  , .groups = "drop")

# Join
zipcode_summary <- rat_summary |>
  left_join(pizza_summary, by = "zipcode")

# Saving zipcode_summary to directory
write_csv(zipcode_summary, "data_small/zipcode_summary.csv")
```



